{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Légszennyezettség mérés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from numpy import genfromtxt\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23623, 31)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_file = '../res/pontbeli_adatok_Budapest_dt_sep.csv'\n",
    "\n",
    "train_data = genfromtxt(train_data_file, delimiter=',', skip_header=1).astype(np.float32)\n",
    "train_data = np.delete(train_data, -1, 1)\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading labels + dates to merge data & labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dates_file = '../res/pontbeli_adatok_Budapest.csv'\n",
    "train_data_dates = []\n",
    "with open(train_dates_file, 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    included_cols = [0]\n",
    "    for row in reader:\n",
    "        train_data_dates.append(list(row[i] for i in included_cols))\n",
    "train_data_dates = train_data_dates[1:]\n",
    "\n",
    "train_labels_file = '../res/Szena_dt_sep.csv'\n",
    "train_labels_raw = []\n",
    "with open(train_labels_file, 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=';')\n",
    "    included_cols = [0, 2]\n",
    "    for row in reader:\n",
    "        train_labels_raw.append(list(row[i] for i in included_cols))\n",
    "# Cut header\n",
    "train_labels_raw = train_labels_raw[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23623\n",
      "119249\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_dates))\n",
    "print(len(train_labels_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels_filtered = np.array([i for i in train_labels_raw if i[1] != ''])\n",
    "t = np.reshape(train_labels_filtered, (-1, 2))\n",
    "train_labels = t[:, 1].astype(np.float32)\n",
    "train_labels_dates = t[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ..., 23617 23618 23619]\n",
      "[ 42579  42582  42585 ..., 108223 108226 108229]\n",
      "21873\n",
      "21873\n"
     ]
    }
   ],
   "source": [
    "indices_train_data = np.nonzero(np.in1d(train_data_dates, train_labels_dates))[0]\n",
    "indices_label = np.nonzero(np.in1d(train_labels_dates, train_data_dates))[0]\n",
    "print(indices_train_data)\n",
    "print(indices_label)\n",
    "print(len(indices_train_data))\n",
    "print(len(indices_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2009-01-01-00-00']\n",
      "['2009-01-01-00-00', '67.0']\n"
     ]
    }
   ],
   "source": [
    "print(train_data_dates[0])\n",
    "print(train_labels_filtered[42579])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0 labels: 17215 (78.70%)\n",
      "Number of 1 labels: 4658 (21.30%)\n"
     ]
    }
   ],
   "source": [
    "data_full = train_data[indices_train_data]\n",
    "label_full_timestamp = train_labels_filtered[indices_label]\n",
    "label_full = train_labels[indices_label]\n",
    "label_full = (label_full > 50).astype(np.float32)\n",
    "cnt_neg = sum(label_full == 0.0)\n",
    "cnt_pos = sum(label_full == 1.0)\n",
    "pct_neg = cnt_neg / len(y) * 100\n",
    "pct_pos = cnt_pos / len(y) * 100\n",
    "print('Number of 0 labels: %d (%.2f%%)' % (cnt_neg, pct_neg))\n",
    "print('Number of 1 labels: %d (%.2f%%)' % (cnt_pos, pct_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.00900000e+03,   1.00000000e+00,   1.00000000e+00,\n",
       "         1.20000000e+01,   0.00000000e+00,   1.02563750e+05,\n",
       "         2.70000005e+00,  -2.59999990e-01,   5.37999992e+01,\n",
       "        -3.98999643e+00,   5.40440002e+02,   0.00000000e+00,\n",
       "         0.00000000e+00,   0.00000000e+00,   7.00000000e+01,\n",
       "         7.84999990e+00,  -4.44000006e+00,  -7.75000620e+00,\n",
       "         4.80000000e+01,   7.07999992e+00,  -8.22000027e+00,\n",
       "        -3.84998178e+00,  -2.77752392e-02,   1.36326337e+00,\n",
       "         5.49558838e+03,   4.62276163e-03,   7.80149102e-02,\n",
       "         1.02563750e+05,   6.83827475e-02,   1.38646388e+00,\n",
       "         1.46758704e+03,   0.00000000e+00])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.ndarray((data_full.shape[0], data_full.shape[1] + 1))\n",
    "data[:, 0:-1] = data_full\n",
    "data[:, data_full.shape[1]] = label_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rnd_indeces = np.arange(len(indices_label))\n",
    "np.random.shuffle(rnd_indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data count: 3726\n",
      "Cross validation data count: 465\n",
      "Test data count: 467\n"
     ]
    }
   ],
   "source": [
    "train_data_cnt = int(cnt_pos * 0.8)\n",
    "valid_data_cnt = int(cnt_pos * 0.1)\n",
    "test_data_cnt = cnt_pos - train_data_cnt - valid_data_cnt\n",
    "\n",
    "print('Train data count: %d' % train_data_cnt)\n",
    "print('Cross validation data count: %d' % valid_data_cnt)\n",
    "print('Test data count: %d' % test_data_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train (80%) - validation (10%) - test (rest) datasets.  \n",
    "Proportion of pos/neg examples in train and valid sets: 50-50  \n",
    "Proportion of pos/neg examples in test set: 3-97 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos data counts:\n",
      "3726\n",
      "465\n",
      "467\n",
      "\n",
      "Neg data counts:\n",
      "3726\n",
      "465\n",
      "13024\n"
     ]
    }
   ],
   "source": [
    "data_pos_idx = np.where(label_full == 1)\n",
    "data_neg_idx = np.where(label_full == 0)\n",
    "\n",
    "data_pos = data[data_pos_idx]\n",
    "data_neg = data[data_neg_idx]\n",
    "\n",
    "train_data_pos = data_pos[0:train_data_cnt]\n",
    "valid_data_pos = data_pos[train_data_cnt:train_data_cnt+valid_data_cnt]\n",
    "test_data_pos = data_pos[train_data_cnt+valid_data_cnt:]\n",
    "\n",
    "train_data_neg = data_neg[0:train_data_cnt]\n",
    "valid_data_neg = data_neg[train_data_cnt:train_data_cnt+valid_data_cnt]\n",
    "test_data_neg = data_neg[train_data_cnt+valid_data_cnt:]\n",
    "\n",
    "print('Pos data counts:')\n",
    "print(len(train_data_pos))\n",
    "print(len(valid_data_pos))\n",
    "print(len(test_data_pos))\n",
    "print('\\nNeg data counts:')\n",
    "print(len(train_data_neg))\n",
    "print(len(valid_data_neg))\n",
    "print(len(test_data_neg))\n",
    "\n",
    "train_data = np.vstack((train_data_neg, train_data_pos))\n",
    "valid_data = np.vstack((valid_data_neg, valid_data_pos))\n",
    "test_data = np.vstack((test_data_neg, test_data_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random shuffle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg data counts:\n",
      "7452\n",
      "930\n",
      "13491\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(train_data)\n",
    "np.random.shuffle(valid_data)\n",
    "np.random.shuffle(test_data)\n",
    "\n",
    "print('Neg data counts:')\n",
    "print(len(train_data))\n",
    "print(len(valid_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save pickles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-9d04b4a53961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Save {} file'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msave_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0msave_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msave_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-295-9d04b4a53961>\u001b[0m in \u001b[0;36msave_pickle\u001b[0;34m(dataset, set_filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Save {} file'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "train_file_name = '../res/input_data/train.pickle'\n",
    "valid_file_name = '../res/input_data/valid.pickle'\n",
    "test_file_name = '../res/input_data/test.pickle'\n",
    "\n",
    "def save_pickle(dataset, set_filename):\n",
    "    with open(set_filename, 'wb') as f:\n",
    "        pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "        print('Save {} file'.format(set_filename))\n",
    "        \n",
    "save_pickle(train_data, train_file_name)\n",
    "save_pickle(valid_data, valid_file_name)\n",
    "save_pickle(test_data, test_file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
